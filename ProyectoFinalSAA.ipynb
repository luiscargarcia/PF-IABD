{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luiscargarcia/PF-IABD/blob/main/ProyectoFinalSAA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "293366ca8145a67b"
      },
      "cell_type": "markdown",
      "source": [
        "# Enunciado del Proyecto Final\n",
        "## Curso de Especialización en Inteligencia Artificial y Big Data\n",
        "\n",
        "## Título del Proyecto: Clasificación de Imágenes mediante Redes Neuronales Convolucionales\n",
        "\n",
        "## 1. **Introducción y contexto**\n",
        "\n",
        "Este proyecto final tiene como objetivo aplicar los conocimientos adquiridos durante el Curso de Especialización en Inteligencia Artificial y Big Data, centrándose en el campo de la Visión por Computador mediante Deep Learning.    \n",
        "\n",
        "El alumnado deberá desarrollar, entrenar y evaluar diferentes modelos de redes neuronales para resolver un problema de clasificación de imágenes utilizando uno de los datasets propuestos.    \n",
        "El alumno deberá usar sus conocimientos para manejar el ciclo de vida completo de un proyecto de IA, desde la carga y preprocesamiento de datos hasta el entrenamiento, evaluación y comparación de modelos, incluyendo técnicas como la construcción de redes desde cero y el Transfer Learning.\n",
        "\n",
        "## 2. **Objetivo General**\n",
        "\n",
        "Desarrollar y evaluar un sistema de clasificación de imágenes utilizando redes neuronales convolucionales (CNNs), comparando el rendimiento de modelos construidos desde cero con modelos basados en Transfer Learning.\n",
        "\n",
        "## 3. **Datasets Propuestos (Seleccionar UNO)**\n",
        "\n",
        "El alumno deberá seleccionar uno de los siguientes datasets para realizar su proyecto. Se recomienda explorar brevemente cada uno antes de tomar una decisión.\n",
        "\n",
        "***CIFAR-10:***\n",
        "\n",
        "- Descripción: Dataset clásico con 60,000 imágenes en color de 32x32 píxeles, distribuidas en 10 clases (aviones, coches, pájaros, gatos, ciervos, perros, ranas, caballos, barcos, camiones). 50,000 para entrenamiento y 10,000 para test.\n",
        "- Fuente: Disponible directamente en Keras/TensorFlow Datasets (tf.keras.datasets.cifar10).\n",
        "- Complejidad: Moderada, ideal para probar arquitecturas rápidamente.\n",
        "\n",
        "***Intel Image Classification (Natural Scenes):***\n",
        "\n",
        "- Descripción: Dataset con aproximadamente 25,000 imágenes de escenas naturales clasificadas en 6 categorías (buildings, forest, glacier, mountain, sea, street). Las imágenes tienen un tamaño de 150x150 píxeles.\n",
        "- Fuente: Disponible en Kaggle (https://www.kaggle.com/datasets/puneet6060/intel-image-classification). Se requiere descarga y organización.\n",
        "- Complejidad: Moderada-Alta, imágenes más grandes y realistas que CIFAR-10.\n",
        "\n",
        "***Flowers-102:***\n",
        "\n",
        "- Descripción: Dataset con 102 categorías de flores comunes en el Reino Unido. Contiene entre 40 y 258 imágenes por clase, con un total de 8,189 imágenes. Las imágenes varían en tamaño.\n",
        "- Fuente: Disponible en TensorFlow Datasets (tensorflow_datasets.load('oxford_flowers102')) o para descarga manual.\n",
        "- Complejidad: Alta, muchas clases con número variable de ejemplos, requiere buen manejo de preprocesamiento y posible desbalanceo.\n",
        "\n",
        "***Waste Classification (TrashNet Modificado):***\n",
        "\n",
        "- Descripción: Dataset con imágenes de residuos clasificadas en categorías como cartón, vidrio, metal, papel, plástico y otros/basura general. Existen varias versiones en Kaggle.\n",
        "- Fuente: Buscar en Kaggle \"Waste Classification Dataset\" (ej: https://www.kaggle.com/datasets/techsash/waste-classification-data). Seleccionar una versión con estructura clara de carpetas por clase.\n",
        "- Complejidad: Moderada-Alta, problema relevante con potencial variabilidad en las imágenes y posible desbalanceo.\n",
        "\n",
        "***Food-101 (Subconjunto Recomendado):***\n",
        "\n",
        "- Descripción: Dataset grande con 101 categorías de comida y 101,000 imágenes. Debido a su tamaño, se recomienda trabajar con un subconjunto (ej. 10-20 clases seleccionadas) o utilizar una versión pre-procesada más pequeña si se encuentra disponible.\n",
        "- Fuente: Disponible en TensorFlow Datasets (tensorflow_datasets.load('food101')). Requiere filtrar clases si se usa un subconjunto.\n",
        "- Complejidad: Alta (incluso con subconjunto), gran variabilidad intra-clase.    \n",
        "\n",
        "## 4. **Tareas a Desarrollar**\n",
        "\n",
        "El proyecto deberá incluir, como mínimo, los siguientes puntos desarrollados en un notebook de Jupyter (o Google Colab):\n",
        "\n",
        "- Selección y Carga del Dataset:\n",
        "    Justificar brevemente la elección del dataset.\n",
        "- Cargar las imágenes y sus etiquetas correspondientes. Organizar los datos si es necesario (ej. desde Kaggle).\n",
        "- Análisis Exploratorio de Datos (EDA):\n",
        "    - Visualizar ejemplos de imágenes de cada clase.\n",
        "    - Analizar las dimensiones de las imágenes y decidir un tamaño estándar para el preprocesamiento.\n",
        "    - Estudiar la distribución de clases (histograma) e identificar posibles desbalanceos.\n",
        "- Preprocesamiento de Datos:\n",
        "    - Redimensionar las imágenes al tamaño estándar elegido.\n",
        "    - Normalizar los valores de los píxeles (ej. rango 0-1).\n",
        "    - Dividir el dataset en conjuntos de entrenamiento, validación y test.\n",
        "    - Considerar la codificación de etiquetas (ej. sparse_categorical_crossentropy o categorical_crossentropy).\n",
        "- Modelo 1: CNN desde Cero:\n",
        "    - Diseñar, construir y compilar una Red Neuronal Convolucional propia. Debe tener al menos 2-3 bloques convolucionales (Conv2D, Activación, Pooling) y una sección de clasificación (Flatten, Dense).\n",
        "    - Entrenar el modelo con el conjunto de entrenamiento.\n",
        "    - Evaluar el modelo en el conjunto de validación durante el entrenamiento (monitorizar curvas de loss y accuracy).\n",
        "    - Evaluar el modelo final en el conjunto de test (reporte de clasificación, matriz de confusión opcional).\n",
        "- Modelo 2: Mejoras (Opcional pero Recomendado):\n",
        "    - Si se detectó desbalanceo en el EDA, aplicar técnicas para mitigarlo (ej. class_weight en model.fit).\n",
        "    - Aplicar técnicas de Data Augmentation utilizando ImageDataGenerator o capas de Keras para aumentar la robustez del modelo y reducir el overfitting.\n",
        "    - Re-entrenar el modelo (o uno nuevo) con estas mejoras y evaluar.\n",
        "- Modelo 3: Transfer Learning:\n",
        "    - Seleccionar una arquitectura pre-entrenada (ej. VGG16, ResNet50V2, MobileNetV2, EfficientNet).\n",
        "    - Cargar el modelo base con pesos pre-entrenados (ej. 'imagenet'), excluyendo la capa superior (include_top=False).\n",
        "    - Congelar las capas del modelo base (trainable = False).\n",
        "    - Añadir un nuevo clasificador (top model) adaptado al número de clases del dataset elegido (Flatten, Dense, Dropout, etc.).\n",
        "    - Aplicar el preprocesamiento específico requerido por la red pre-entrenada (si lo tiene).\n",
        "    - Compilar y entrenar únicamente el nuevo clasificador.\n",
        "    - Evaluar el modelo final en el conjunto de test.\n",
        "    - (Opcional Avanzado): Realizar Fine-Tuning (descongelar algunas capas superiores del modelo base y re-entrenar con una tasa de aprendizaje muy baja).\n",
        "- Comparación y Conclusiones:\n",
        "    - Presentar una tabla o resumen comparando las métricas clave (accuracy, precision, recall, F1-score) de los modelos desarrollados (CNN desde cero, CNN mejorada, Transfer Learning).\n",
        "    - Discutir los resultados obtenidos: ¿Qué modelo funcionó mejor y por qué? ¿Qué desafíos se encontraron (overfitting, desbalanceo, tiempo de entrenamiento)?\n",
        "    - Proponer posibles líneas de mejora futuras.   \n",
        "\n",
        "## 5. **Herramientas**\n",
        "\n",
        "- Lenguaje: Python 3.x   \n",
        "- Librerías Principales: TensorFlow, Keras, Scikit-learn, NumPy, Pandas (opcional, para manejo de datos), Matplotlib, Seaborn.   \n",
        "- Entorno: Jupyter Notebook o Google Colab (recomendado por la disponibilidad de GPUs gratuitas).   \n",
        "\n",
        "## 6. **Entregable**\n",
        "\n",
        "Un único archivo de Jupyter Notebook (.ipynb) que contenga:   \n",
        "   - Todo el código Python ejecutado.    \n",
        "   - Resultados de la ejecución de las celdas (salidas, gráficas).   \n",
        "   - Texto en formato Markdown explicando cada paso, las decisiones tomadas, el análisis de los resultados y las conclusiones finales.   \n",
        "\n",
        "## 7. **Criterios de Evaluación**\n",
        "\n",
        "- Funcionalidad: El código es ejecutable y realiza las tareas solicitadas.\n",
        "- Claridad del Código: Código bien estructurado, comentado y legible.\n",
        "- Metodología: Correcta aplicación de las técnicas de preprocesamiento, modelado y evaluación.\n",
        "- Análisis y Discusión: Profundidad y coherencia del análisis de resultados y las conclusiones.\n",
        "- Presentación: Claridad y organización del notebook.\n",
        "- Rendimiento del Modelo: Se valorará el esfuerzo por obtener modelos con buen rendimiento, aunque el resultado final no sea perfecto."
      ],
      "id": "293366ca8145a67b"
    },
    {
      "metadata": {
        "id": "68dc4f03cbb7bbe2"
      },
      "cell_type": "markdown",
      "source": [
        "# Proyecto Final - Curso Especialización IA y Big Data CyL\n",
        "\n",
        "## Nombre Alumno: [Tu Nombre Aquí]\n",
        "## Dataset Elegido: [Nombre del Dataset]\n"
      ],
      "id": "68dc4f03cbb7bbe2"
    },
    {
      "metadata": {
        "id": "9b1c1f49ad30217a"
      },
      "cell_type": "markdown",
      "source": [
        "## 0. CONFIGURACIÓN INICIAL\n",
        "### 0.1 Importar librerías"
      ],
      "id": "9b1c1f49ad30217a"
    },
    {
      "metadata": {
        "id": "c37d4efd86f28e01"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.applications import VGG16, ResNet50V2, MobileNetV2 # Ejemplo, añadir/quitar según necesidad\n",
        "from tensorflow.keras.applications import vgg16, resnet_v2, mobilenet_v2 # Para preprocesamiento específico\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils import class_weight\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "\n",
        "# Para conectar con Google Drive (si se usa Colab)\n",
        "# from google.colab import drive, files\n",
        "\n",
        "print(\"Versión de TensorFlow:\", tf.__version__)\n",
        "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU'))) # Descomentar para verificar GPU"
      ],
      "id": "c37d4efd86f28e01"
    },
    {
      "metadata": {
        "id": "f82fc76dfa705cf0"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 0.2. Configuración de Semillas y Parámetros Globales"
      ],
      "id": "f82fc76dfa705cf0"
    },
    {
      "metadata": {
        "id": "dc2a03324102dec2"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# Parámetros (ajustar según dataset y pruebas)\n",
        "IMAGE_WIDTH = 224  # Ejemplo, ajustar al dataset o red pre-entrenada\n",
        "IMAGE_HEIGHT = 224 # Ejemplo, ajustar al dataset o red pre-entrenada\n",
        "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS = 3\n",
        "BATCH_SIZE = 32  # Ajustar según memoria disponible\n",
        "EPOCHS_SCRATCH = 30 # Épocas para modelo desde cero\n",
        "EPOCHS_TRANSFER = 20 # Épocas para transfer learning (puede ser menos)"
      ],
      "id": "dc2a03324102dec2"
    },
    {
      "metadata": {
        "id": "2d489e5ad4ee295b"
      },
      "cell_type": "markdown",
      "source": [
        "### 0.3. Definición de Rutas (si aplica) - En Google Colab"
      ],
      "id": "2d489e5ad4ee295b"
    },
    {
      "metadata": {
        "id": "f64aff559ec706c"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "\n",
        "# Ejemplo si se usa Google Drive en Colab\n",
        "# drive.mount('/content/drive')\n",
        "# BASE_FOLDER = '/content/drive/MyDrive/ProyectoFinalIA/'\n",
        "# DATA_FOLDER = os.path.join(BASE_FOLDER, 'data') # Carpeta donde descargar/descomprimir datos\n",
        "# MODEL_FOLDER = os.path.join(BASE_FOLDER, 'models') # Carpeta para guardar modelos entrenados\n",
        "\n",
        "# Ejemplo si se trabaja localmente o en Colab sin Drive\n",
        "DATA_FOLDER = './data/'\n",
        "MODEL_FOLDER = './models/'\n",
        "\n",
        "# Crear carpetas si no existen\n",
        "# os.makedirs(DATA_FOLDER, exist_ok=True)\n",
        "# os.makedirs(MODEL_FOLDER, exist_ok=True)\n"
      ],
      "id": "f64aff559ec706c"
    },
    {
      "metadata": {
        "id": "cb55bf53e8df6c89"
      },
      "cell_type": "markdown",
      "source": [
        "### 0.4. Funciones Auxiliares (Ejemplo: Plotear Curvas)"
      ],
      "id": "cb55bf53e8df6c89"
    },
    {
      "metadata": {
        "id": "738a176abe68e278"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "def plot_learning_curves(history, epochs, title_suffix=''):\n",
        "    \"\"\"Plotea las curvas de loss y accuracy para entrenamiento y validación.\"\"\""
      ],
      "id": "738a176abe68e278"
    },
    {
      "metadata": {
        "id": "f48adb03b4341550"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. SELECCIÓN Y CARGA DEL DATASET"
      ],
      "id": "f48adb03b4341550"
    },
    {
      "metadata": {
        "id": "dbea5741eae13bbe"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "print(\"\\n--- 1. Carga del Dataset ---\")"
      ],
      "id": "dbea5741eae13bbe"
    },
    {
      "metadata": {
        "id": "8b8332734ab9bd08"
      },
      "cell_type": "markdown",
      "source": [
        "#### 1.1. Descarga y Descompresión (si es necesario, ej. desde Kaggle)"
      ],
      "id": "8b8332734ab9bd08"
    },
    {
      "metadata": {
        "id": "3664c9e136beb8f5"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Ejemplo si se usa Kaggle API en Colab:\n",
        "# !pip install kaggle --upgrade\n",
        "# files.upload() # Subir kaggle.json\n",
        "# !mkdir -p ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n",
        "# !kaggle datasets download -d puneet6060/intel-image-classification -p {DATA_FOLDER} --unzip\n",
        "\n",
        "# O si se descarga un ZIP manualmente:\n",
        "# zip_path = os.path.join(DATA_FOLDER, 'nombre_archivo.zip')\n",
        "# extract_path = os.path.join(DATA_FOLDER, 'nombre_dataset')\n",
        "# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "#     zip_ref.extractall(extract_path)\n",
        "# print(f\"Dataset descomprimido en: {extract_path}\")\n",
        "\n",
        "# Definir la ruta principal al dataset descomprimido\n",
        "# dataset_path = extract_path # O la ruta directa si ya está descargado\n",
        "\n",
        "# --- TU CÓDIGO AQUÍ ---\n",
        "# Asegúrate de que 'dataset_path' apunte a la carpeta principal del dataset\n",
        "# que contiene subcarpetas para train/test o directamente las clases.\n",
        "# dataset_path = os.path.join(DATA_FOLDER, 'intel-image-classification/seg_train/seg_train') # Ejemplo Intel\n",
        "\n",
        "# --- FIN TU CÓDIGO ---"
      ],
      "id": "3664c9e136beb8f5"
    },
    {
      "metadata": {
        "id": "34d2c311484c028"
      },
      "cell_type": "markdown",
      "source": [
        "#### 1.2. Carga del dataset"
      ],
      "id": "34d2c311484c028"
    },
    {
      "metadata": {
        "id": "886bee26f4a09dda"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# --- TU CÓDIGO AQUÍ ---\n",
        "# Carga los datos.\n",
        "# --- FIN TU CÓDIGO ---"
      ],
      "id": "886bee26f4a09dda"
    },
    {
      "metadata": {
        "id": "368944de63875c07"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. ANÁLISIS EXPLORATORIO DE DATOS (EDA)"
      ],
      "id": "368944de63875c07"
    },
    {
      "metadata": {
        "id": "69143ea7d452ace3"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "print(\"\\n--- 2. Análisis Exploratorio de Datos (EDA) ---\")"
      ],
      "id": "69143ea7d452ace3"
    },
    {
      "metadata": {
        "id": "80e9e49fd91e4618"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 2.1. Visualización de Muestras"
      ],
      "id": "80e9e49fd91e4618"
    },
    {
      "metadata": {
        "id": "4d7e2de147745de1"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# --- TU CÓDIGO AQUÍ ---\n",
        "# Muestra algunas imágenes del conjunto de entrenamiento con sus etiquetas\n",
        "# --- FIN TU CÓDIGO ---"
      ],
      "id": "4d7e2de147745de1"
    },
    {
      "metadata": {
        "id": "ca21ef9918cce8ce"
      },
      "cell_type": "markdown",
      "source": [
        "#### 2.2. Análisis de Dimensiones y Formato"
      ],
      "id": "ca21ef9918cce8ce"
    },
    {
      "metadata": {
        "id": "217f6f1bdeccc7b8"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# --- TU CÓDIGO AQUÍ ---\n",
        "# Verifica las dimensiones de las imágenes cargadas y el formato de las etiquetas\n",
        "# --- FIN TU CÓDIGO ---"
      ],
      "id": "217f6f1bdeccc7b8"
    },
    {
      "metadata": {
        "id": "c7d7b120ce60b630"
      },
      "cell_type": "markdown",
      "source": [
        "#### 2.3. Distribución de Clases"
      ],
      "id": "c7d7b120ce60b630"
    },
    {
      "metadata": {
        "id": "7cf06c5e6d53157"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# --- TU CÓDIGO AQUÍ ---\n",
        "# Calcula y visualiza cuántas imágenes hay por cada clase en el conjunto de entrenamiento\n",
        "# Esto es crucial para detectar desbalanceo.\n",
        "# --- FIN TU CÓDIGO ---"
      ],
      "id": "7cf06c5e6d53157"
    },
    {
      "metadata": {
        "id": "3d0b64e40123493a"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 3. PREPROCESAMIENTO DE DATOS"
      ],
      "id": "3d0b64e40123493a"
    },
    {
      "metadata": {
        "id": "cce18ed5e74cab2b"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "print(\"\\n--- 3. Preprocesamiento de Datos ---\")"
      ],
      "id": "cce18ed5e74cab2b"
    },
    {
      "metadata": {
        "id": "f34f1304b06df8e7"
      },
      "cell_type": "markdown",
      "source": [
        "#### 3.1. Normalización / Escalado"
      ],
      "id": "f34f1304b06df8e7"
    },
    {
      "metadata": {
        "id": "95088da671911822"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# --- TU CÓDIGO AQUÍ ---\n",
        "# Aplicar normalización a los píxeles (usualmente a rango 0-1 o -1 a 1)\n",
        "# Se puede hacer con una capa de Keras (Rescaling) o manualmente.\n",
        "# --- FIN TU CÓDIGO ---"
      ],
      "id": "95088da671911822"
    },
    {
      "metadata": {
        "id": "50d63686ac2da625"
      },
      "cell_type": "markdown",
      "source": [
        "#### 3.2. División en Train / Validation / Test"
      ],
      "id": "50d63686ac2da625"
    },
    {
      "metadata": {
        "id": "6993e9fb1b4f67c4"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Conjuntos separados para entrenar, ajustar hiperparámetros\n",
        "# y evaluar el rendimiento final de forma imparcial.\n",
        "\n",
        "# --- TU CÓDIGO AQUÍ ---\n",
        "\n",
        "# --- FIN TU CÓDIGO ---"
      ],
      "id": "6993e9fb1b4f67c4"
    },
    {
      "metadata": {
        "id": "f2b85f09d9a2a472"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. MODELO 1: CNN DESDE CERO"
      ],
      "id": "f2b85f09d9a2a472"
    },
    {
      "metadata": {
        "id": "92a07f62c8054138"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "print(\"\\n--- 4. Modelo 1: CNN desde Cero ---\")"
      ],
      "id": "92a07f62c8054138"
    },
    {
      "metadata": {
        "id": "46dc727c146dcacb"
      },
      "cell_type": "markdown",
      "source": [
        "#### 4.1. Construcción de la Arquitectura"
      ],
      "id": "46dc727c146dcacb"
    },
    {
      "metadata": {
        "id": "dd143395edea334e"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# --- TU CÓDIGO AQUÍ ---\n",
        "# Define tu modelo CNN secuencial. Asegúrate que la capa de entrada\n",
        "# coincida con IMAGE_SIZE y IMAGE_CHANNELS. La salida debe tener NUM_CLASSES neuronas.\n",
        "# --- FIN TU CÓDIGO ---"
      ],
      "id": "dd143395edea334e"
    },
    {
      "metadata": {
        "id": "1193dee07b9fdaf8"
      },
      "cell_type": "markdown",
      "source": [
        "#### 4.2. Compilación del Modelo"
      ],
      "id": "1193dee07b9fdaf8"
    },
    {
      "metadata": {
        "id": "63914840a6071315"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# --- TU CÓDIGO AQUÍ ---\n",
        "# Elige un optimizador, una función de pérdida y métricas\n",
        "# --- FIN TU CÓDIGO ---"
      ],
      "id": "63914840a6071315"
    },
    {
      "metadata": {
        "id": "f1cb018ea8bb3478"
      },
      "cell_type": "markdown",
      "source": [
        "#### 4.3. Entrenamiento del Modelo"
      ],
      "id": "f1cb018ea8bb3478"
    },
    {
      "metadata": {
        "id": "beaaad0981872243"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# --- TU CÓDIGO AQUÍ ---\n",
        "# Define callbacks (EarlyStopping es muy recomendable)\n",
        "# --- FIN TU CÓDIGO ---"
      ],
      "id": "beaaad0981872243"
    },
    {
      "metadata": {
        "id": "f4c0b5f540285ee3"
      },
      "cell_type": "markdown",
      "source": [
        "#### 4.4. Evaluación del Modelo"
      ],
      "id": "f4c0b5f540285ee3"
    },
    {
      "metadata": {
        "id": "cfe8b2f313cde6ce"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# --- TU CÓDIGO AQUÍ ---\n",
        "# Cargar el mejor modelo guardado por ModelCheckpoint\n",
        "\n",
        "# Evaluar en el conjunto de test\n",
        "\n",
        "# Generar reporte de clasificación\n",
        "\n",
        "# Visualizar curvas de aprendizaje\n",
        "\n",
        "# --- FIN TU CÓDIGO ---"
      ],
      "id": "cfe8b2f313cde6ce"
    },
    {
      "metadata": {
        "id": "c57e9ed4df8a7139"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 5. MODELO 2: MEJORAS (DATA AUGMENTATION / CLASS WEIGHTING)"
      ],
      "id": "c57e9ed4df8a7139"
    },
    {
      "metadata": {
        "id": "d9bf42fd7fa859e9"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "print(\"\\n--- 5. Modelo 2: Mejoras (Data Augmentation / Class Weighting) ---\")\n",
        "# Esta sección es opcional pero muy recomendada, especialmente si hay overfitting o desbalanceo"
      ],
      "id": "d9bf42fd7fa859e9"
    },
    {
      "metadata": {
        "id": "f78867f4f702b86b"
      },
      "cell_type": "markdown",
      "source": [
        "#### 5.1. Cálculo de Pesos de Clase (si hay desbalanceo)"
      ],
      "id": "f78867f4f702b86b"
    },
    {
      "metadata": {
        "id": "9bd09e6d1037aa9d"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# --- TU CÓDIGO AQUÍ ---\n",
        "# Si el EDA mostró desbalanceo, calcula los pesos\n",
        "# --- FIN TU CÓDIGO ---"
      ],
      "id": "9bd09e6d1037aa9d"
    },
    {
      "metadata": {
        "id": "632d520ff22e0783"
      },
      "cell_type": "markdown",
      "source": [
        "#### 5.2. Definición de Data Augmentation"
      ],
      "id": "632d520ff22e0783"
    },
    {
      "metadata": {
        "id": "8b284be2d9e0303e"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Se puede hacer con capas de Keras o con ImageDataGenerator\n",
        "# --- TU CÓDIGO AQUÍ ---\n",
        "\n",
        "# --- FIN TU CÓDIGO ---"
      ],
      "id": "8b284be2d9e0303e"
    },
    {
      "metadata": {
        "id": "47ad8b7097bb98da"
      },
      "cell_type": "markdown",
      "source": [
        "#### 5.3. Construcción y Entrenamiento del Modelo Mejorado"
      ],
      "id": "47ad8b7097bb98da"
    },
    {
      "metadata": {
        "id": "635afd93c7721216"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# --- TU CÓDIGO AQUÍ ---\n",
        "# Puedes reutilizar la arquitectura de `model_scratch` o definir una nueva.\n",
        "# Si usas capas de augmentation, añádelas al principio.\n",
        "# --- FIN TU CÓDIGO ---"
      ],
      "id": "635afd93c7721216"
    },
    {
      "metadata": {
        "id": "bb39fbf6355f281d"
      },
      "cell_type": "markdown",
      "source": [
        "#### 5.4. Evaluación del Modelo Mejorado"
      ],
      "id": "bb39fbf6355f281d"
    },
    {
      "metadata": {
        "id": "52c4f9fee422b01"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# --- TU CÓDIGO AQUÍ ---\n",
        "# Cargar el mejor modelo guardado\n",
        "\n",
        "# Evaluar en el conjunto de test\n",
        "\n",
        "# Generar reporte de clasificación\n",
        "\n",
        "# Visualizar curvas de aprendizaje\n",
        "\n",
        "# --- FIN TU CÓDIGO ---"
      ],
      "id": "52c4f9fee422b01"
    },
    {
      "metadata": {
        "id": "8973e7ae9075d982"
      },
      "cell_type": "markdown",
      "source": [
        "## 6. MODELO 3: TRANSFER LEARNING"
      ],
      "id": "8973e7ae9075d982"
    },
    {
      "metadata": {
        "id": "ae3273cd428065ec"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "print(\"\\n--- 6. Modelo 3: Transfer Learning ---\")"
      ],
      "id": "ae3273cd428065ec"
    },
    {
      "metadata": {
        "id": "78008cc6e578c552"
      },
      "cell_type": "markdown",
      "source": [
        "### 6.1. Selección y Carga del Modelo Base Pre-entrenado"
      ],
      "id": "78008cc6e578c552"
    },
    {
      "metadata": {
        "id": "423ee7c7c3ae4f9e"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# --- TU CÓDIGO AQUÍ ---\n",
        "# Elige una red base (VGG16, ResNet50V2, MobileNetV2, etc.)\n",
        "# Asegúrate que IMAGE_SIZE sea compatible con la red elegida (ej. 224x224 para muchas)\n",
        "# --- FIN TU CÓDIGO ---"
      ],
      "id": "423ee7c7c3ae4f9e"
    },
    {
      "metadata": {
        "id": "7525344eb96be522"
      },
      "cell_type": "markdown",
      "source": [
        "### 6.2. Creación del Nuevo Modelo (Base + Clasificador Propio)"
      ],
      "id": "7525344eb96be522"
    },
    {
      "metadata": {
        "id": "e1a947edd73a8da8"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# --- TU CÓDIGO AQUÍ ---\n",
        "# Define el preprocesamiento específico de la red elegida\n",
        "# --- FIN TU CÓDIGO ---"
      ],
      "id": "e1a947edd73a8da8"
    },
    {
      "metadata": {
        "id": "d591c3e4aeabf6d4"
      },
      "cell_type": "markdown",
      "source": [
        "### 6.3. Compilación y Entrenamiento (solo del clasificador)"
      ],
      "id": "d591c3e4aeabf6d4"
    },
    {
      "metadata": {
        "id": "22ccb97b96e8ca0f"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# --- TU CÓDIGO AQUÍ ---\n",
        "# Compilar el modelo\n",
        "\n",
        "# Definir callbacks\n",
        "\n",
        "# --- FIN TU CÓDIGO ---"
      ],
      "id": "22ccb97b96e8ca0f"
    },
    {
      "metadata": {
        "id": "4199f1b61f8f357d"
      },
      "cell_type": "markdown",
      "source": [
        "### 6.4. Evaluación del Modelo de Transfer Learning\n"
      ],
      "id": "4199f1b61f8f357d"
    },
    {
      "metadata": {
        "id": "d06734b39bf0781e"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# --- TU CÓDIGO AQUÍ ---\n",
        "# Cargar el mejor modelo guardado\n",
        "\n",
        "# Evaluar en el conjunto de test\n",
        "\n",
        "# Generar reporte de clasificación\n",
        "\n",
        "# Necesitas y_true_test (calculado en 4.4)\n",
        "\n",
        "# Visualizar curvas de aprendizaje\n",
        "\n",
        "# --- FIN TU CÓDIGO ---"
      ],
      "id": "d06734b39bf0781e"
    },
    {
      "metadata": {
        "id": "8c4bb3d5c9fd8e7d"
      },
      "cell_type": "markdown",
      "source": [
        "### 6.5. Fine-Tuning (Opcional)"
      ],
      "id": "8c4bb3d5c9fd8e7d"
    },
    {
      "metadata": {
        "id": "429e9a0d9a80ad20"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "\n",
        "# --- TU CÓDIGO AQUÍ ---\n",
        "# Descongela algunas capas superiores del modelo base\n",
        "\n",
        "# Entrena unas pocas épocas más\n",
        "\n",
        "# # Evaluar el modelo fine-tuned de forma similar a 6.4\n",
        "# --- FIN TU CÓDIGO ---"
      ],
      "id": "429e9a0d9a80ad20"
    },
    {
      "metadata": {
        "id": "ea39b9a06f7649b9"
      },
      "cell_type": "markdown",
      "source": [
        "## 7. COMPARACIÓN DE MODELOS Y CONCLUSIONES"
      ],
      "id": "ea39b9a06f7649b9"
    },
    {
      "metadata": {
        "id": "47c091faf52aeb40"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "print(\"\\n--- 7. Comparación y Conclusiones ---\")"
      ],
      "id": "47c091faf52aeb40"
    },
    {
      "metadata": {
        "id": "d4e6aec7c4bce5d0"
      },
      "cell_type": "markdown",
      "source": [
        "### 7.1. Tabla Comparativa de Resultados"
      ],
      "id": "d4e6aec7c4bce5d0"
    },
    {
      "metadata": {
        "id": "9b164840e92e1cce"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# --- TU CÓDIGO AQUÍ ---\n",
        "# Crea una tabla (puedes usar print o librerías como Pandas) resumiendo\n",
        "# las métricas clave (Accuracy, Precision, Recall, F1-Score en Test)\n",
        "# para cada modelo entrenado (CNN Scratch, CNN Augmented, Transfer Learning, Fine-Tuned).\n",
        "\n",
        "# Se recomienda extraer las métricas del classification_report para una comparación más detallada.\n",
        "# --- FIN TU CÓDIGO ---"
      ],
      "id": "9b164840e92e1cce"
    },
    {
      "metadata": {
        "id": "4486052712974be8"
      },
      "cell_type": "markdown",
      "source": [
        "### 7.2. Discusión y Conclusiones Finales"
      ],
      "id": "4486052712974be8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "# --- ESCRIBE TU ANÁLISIS AQUÍ (en celdas Markdown) ---\n",
        "# * Comenta cuál modelo obtuvo el mejor rendimiento general y por qué crees que fue así.\n",
        "# * Analiza las curvas de aprendizaje: ¿Hubo overfitting? ¿Ayudó el Data Augmentation?\n",
        "# * ¿Cómo afectó el Transfer Learning al rendimiento y al tiempo de entrenamiento (observado)?\n",
        "# * ¿Fue útil el Fine-Tuning (si se realizó)?\n",
        "# * Menciona los principales desafíos encontrados durante el proyecto (carga de datos, preprocesamiento, entrenamiento, ajuste de hiperparámetros).\n",
        "# * Propón posibles mejoras o siguientes pasos que podrían realizarse.\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "print(\"\\n--- Fin del Proyecto ---\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}